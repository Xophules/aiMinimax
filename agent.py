#!/usr/bin/env python3

from ...lib.game import Agent, RandomAgent, GreedyAgent
import math


class MinimaxAgent(Agent):
	"""An agent that makes decisions using the Minimax algorithm, using a
	evaluation function to approximately guess how good certain states
	are when looking far into the future.

	:param evaluation_function: The function used to make evaluate a
		GameState. Should have the parameters (state, player_id) where
		`state` is the GameState and `player_id` is the ID of the
		player to calculate the expected payoff for.

	:param alpha_beta_pruning: True if you would like to use
		alpha-beta pruning.

	:param max_depth: The maximum depth to search using the minimax
		algorithm, before using estimates generated by the evaluation
		function.
	"""

	def __init__(self, evaluate_function, alpha_beta_pruning=False, max_depth=5):
		super().__init__()
		self.evaluate = evaluate_function
		self.alpha_beta_pruning = alpha_beta_pruning
		self.max_depth = max_depth

	def decide(self, state):
		# TODO: Implement this agent!
		#
		# Read the documentation in /src/lib/game/_game.py for
		# information on what the decide function does.
		#
		# Do NOT call the soccer evaluation function that you write
		# directly from this function! Instead, use
		# `self.evaluate`. It will behave identically, but will be
		# able to work for multiple games.
		#
		# Do NOT call any SoccerState-specific functions! Assume that
		# you can only see the functions provided in the GameState
		# class.
		#
		# If you would like to see some example agents, check out
		# `/src/lib/game/_agents.py`.
		if not self.alpha_beta_pruning:
			# return self.maxValue(state, state.current_player, 0)
			a = self.minimax(state, state.current_player)
			print("Desition made: ", a)
			return a
		else:
			return self.minimax_with_ab_pruning(state, state.current_player)

	def maxValue(self, state, player, depth):
		if state is None:
			return math.inf * -1

		if state.is_terminal:
			return state.reward(player)

		# print(depth, self.max_depth)
		if depth > self.max_depth:
			return self.evaluate(state, player)

		v = math.inf * -1
		# print(v)
		for a in state.actions:
			print("MAX On action:", a)
			# print(v, self.minValue(state.act(a), player, depth + 1) )
			v = max(v, self.minValue(state.act(a), player, depth + 1))
		return v

	def minValue(self, state, player, depth):
		if state is None:
			# print("Min None==============")
			return math.inf * -1

		if state.is_terminal:
			# print("Min End==============")
			return state.reward(player)
		# print(depth, self.max_depth)
		if depth > self.max_depth:
			# print("Min Max_depth==============")
			return self.evaluate(state, player)
		v = math.inf
		# print("Depth:", depth, "state.actions:", state.actions)
		for a in state.actions:
			print("MIN On action:", a)
			v = min(v, self.maxValue(state.act(a), player, depth + 1))
		return v

	def minimax(self, state, player, depth=1):
		# This is the suggested method you use to do minimax.  Assume
		# `state` is the current state, `player` is the player that
		# the agent is representing (NOT the current player in
		# `state`!)  and `depth` is the current depth of recursion.

		# return super().decide(state)
		bestVal = math.inf * -1
		best = None
		for a in state.actions:
			u = self.maxValue(state.act(a), state.current_player, 0)
			if u > bestVal:
				best = a

		return best

	def maxValueAB(self, state, player, depth=1, a=float('inf'), b=-float('inf')):
		if state is None:
			return math.inf * -1

		if state.is_terminal:
			return state.reward(player)

		# print(depth, self.max_depth)
		if depth > self.max_depth:
			return self.evaluate(state, player)
		v = math.inf * -1
		for ac in state.actions:
			v = max(v, self.minValueAB(state.act(ac), player, depth + 1, a, b))
			if v >= b:
				return v
			a = max(a, v)

		return v

	def minValueAB(self, state, player, depth=1, a=float('inf'), b=-float('inf')):
		if state is None:
			return math.inf * -1

		if state.is_terminal:
			return state.reward(player)

		# print(depth, self.max_depth)
		if depth > self.max_depth:
			return self.evaluate(state, player)

		v = math.inf
		for ac in state.actions:
			v = min(v, self.maxValueAB(state.act(ac), player, depth + 1, a, b))
			if v <= a:
				return v
			b = min(b, v)

		return v

	def minimax_with_ab_pruning(self, state, player, depth=1,
								alpha=float('inf'), beta=-float('inf')):
		#v = self.maxValueAB(state, player, depth, alpha, beta)

		bestVal = math.inf * -1
		i = 0
		for a in state.actions:
			if i == 0:
				best = a
				i = 1
			u = self.maxValueAB(state.act(a), state.current_player, 0, alpha, beta)
			if u > bestVal:
				best = a

		return best

